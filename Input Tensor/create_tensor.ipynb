{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43751d38-2ef7-4538-9ede-ffffcebee099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import ast\n",
    "import torch\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "385db2ac-ba4b-4381-8d6f-05059dc8e1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bounding_box(bbox_str):\n",
    "    bbox = ast.literal_eval(bbox_str)\n",
    "    return bbox[0], bbox[1], bbox[2], bbox[3]\n",
    "\n",
    "def parse_control_point(point_str):\n",
    "    point = ast.literal_eval(point_str)\n",
    "    return point[0], point[1]\n",
    "\n",
    "def find_notehead(noteheads, x_ref, y_ref, x_range_min, x_range_max):\n",
    "    candidates = []\n",
    "    \n",
    "    for _, note in noteheads.iterrows():\n",
    "        x_min, y_min, x_max, y_max = parse_bounding_box(note[\"BoundingBox\"])\n",
    "        if 1400 <= note[\"Area\"] <= 2400:  # Valid notehead size\n",
    "            if y_min > y_ref and x_range_min <= x_min <= x_range_max:\n",
    "                candidates.append((y_min, x_min, x_max, y_max))\n",
    "\n",
    "    if candidates:\n",
    "        candidates.sort()  # Select the topmost notehead\n",
    "        y_min, x_min, x_max, y_max = candidates[0]\n",
    "        return x_min, y_min, x_max, y_max\n",
    "    return None\n",
    "\n",
    "def note_mask(img, note):\n",
    "    x_min, y_min, x_max, y_max = map(int, note)\n",
    "    mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Extract notehead\n",
    "    note_region = img_gray[y_min:y_max, x_min:x_max]\n",
    "    binary_region = (note_region < 64).astype(np.uint8)\n",
    "    mask[y_min:y_max, x_min:x_max] = binary_region\n",
    "\n",
    "    height, width = img_gray.shape\n",
    "    # Left stem detection\n",
    "    for x in range(max(0, x_min - 4), x_min + 8):\n",
    "        y = y_max\n",
    "        while y + 32 < height and np.all(img_gray[y:y + 32, x] < 64):\n",
    "            mask[y:y + 32, x] = 1\n",
    "            y += 4\n",
    "\n",
    "    # Right stem detection\n",
    "    for x in range(x_max - 8, min(width, x_max + 4)):\n",
    "        y = y_min\n",
    "        while y - 32 > 0 and np.all(img_gray[y - 32:y, x] < 64):\n",
    "            mask[y - 32:y, x] = 1\n",
    "            y -= 4\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16c0012e-9987-4556-a600-9123db17b075",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Tensors: 100%|█████████████████████████████████████████████████████████████| 634/634 [00:05<00:00, 116.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tensors created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tensor_folder = \"tensors\"\n",
    "os.makedirs(tensor_folder, exist_ok=True)\n",
    "failed_folder = \"failed\"\n",
    "os.makedirs(failed_folder, exist_ok=True)\n",
    "error_log_path = \"tensor_error.log\"\n",
    "\n",
    "control_points_df = pd.read_csv(\"control_points.csv\")\n",
    "notehead_detection_df = pd.read_csv(\"notehead_detection.csv\")\n",
    "valid_rows = control_points_df[control_points_df[\"Invalid Bezier Curve\"] == 0]\n",
    "\n",
    "for _, row in tqdm(valid_rows.iterrows(), total=len(valid_rows), desc=\"Creating Tensors\"):\n",
    "    try:\n",
    "        crop_file_name = row[\"Crop File Name\"]\n",
    "        x_P0, y_P0 = parse_control_point(row[\"P0\"])\n",
    "        x_P4, y_P4 = parse_control_point(row[\"P4\"])\n",
    "\n",
    "        noteheads = notehead_detection_df[notehead_detection_df[\"File Name\"] == crop_file_name]\n",
    "        start_note = find_notehead(noteheads, x_P0, y_P0, x_P0 - 65, x_P0)  # Based on notehead size\n",
    "        end_note = find_notehead(noteheads, x_P4, y_P4, x_P4 - 55, x_P4)  # Based on notehead size\n",
    "\n",
    "        img_path = os.path.join(\"Use\", crop_file_name)\n",
    "        slur_erased_path = os.path.join(\"Erase Slur\", f\"e_{crop_file_name}\")\n",
    "        img = cv2.imread(img_path)\n",
    "        slur_erased_img = cv2.imread(slur_erased_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        start_note_mask = note_mask(img, start_note)    # Channel 1\n",
    "        end_note_mask = note_mask(img, end_note)        # Channel 4\n",
    "\n",
    "        # Extract staff lines using histogram method\n",
    "        binary = (slur_erased_img < 64).astype(np.uint8)\n",
    "        row_pixel_count = np.sum(binary > 0, axis=1)  # Count black pixels per row\n",
    "        max_pixel_count = np.max(row_pixel_count)  # Usually equal to image width\n",
    "        rows_to_remove = set(np.where(row_pixel_count > 0.9 * max_pixel_count)[0])  # PARAMETER\n",
    "        \n",
    "        # Remove neighboring rows if above threshold\n",
    "        for row in list(rows_to_remove):\n",
    "            for neighbor in [row - 1, row + 1]:  # PARAMETER\n",
    "                if 0 <= neighbor < binary.shape[0] and row_pixel_count[neighbor] > 0.2 * max_pixel_count:\n",
    "                    rows_to_remove.add(neighbor)  # Remove neighboring row if above the 20% threshold\n",
    "        rows_to_remove = sorted(rows_to_remove)\n",
    "        \n",
    "        staff_line_mask = np.zeros_like(binary, dtype=np.uint8)\n",
    "        staff_line_mask[rows_to_remove, :] = 1    # Channel 3\n",
    "\n",
    "        music_symbols_mask = np.logical_and(binary, np.logical_not(staff_line_mask)).astype(np.uint8)\n",
    "\n",
    "        tensor = np.stack([start_note_mask, music_symbols_mask, staff_line_mask, end_note_mask], axis=0)\n",
    "        tensor = torch.tensor(tensor, dtype=torch.uint8)\n",
    "        tensor_path = os.path.join(tensor_folder, crop_file_name.replace(\".png\", \".pt\"))\n",
    "        torch.save(tensor, tensor_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        with open(error_log_path, \"a\") as error_log:\n",
    "            error_log.write(f\"{crop_file_name}: {e}\\n\")\n",
    "        failed_path = os.path.join(failed_folder, crop_file_name)\n",
    "        shutil.copy(img_path, failed_path)\n",
    "\n",
    "print(\"All tensors created.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
