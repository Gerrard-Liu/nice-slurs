{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","mount_file_id":"1aXSlks3Dwhkz5yrBddHBGjNVkv1d1sRY","authorship_tag":"ABX9TyPwk+Q5hIs0y4KaLd4Z0vbB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"dc9jPzyfkPgd","executionInfo":{"status":"ok","timestamp":1742756911178,"user_tz":240,"elapsed":15812,"user":{"displayName":"Chang Liu","userId":"14973576905763553042"}},"outputId":"dfdc6af6-b06e-4353-c400-9feb566fd1a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyyaml==5.1\n","  Downloading PyYAML-5.1.tar.gz (274 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/274.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.2/274.2 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n","\n","\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n","\u001b[1;36mhint\u001b[0m: See above for details.\n","Cloning into 'detectron2'...\n","remote: Enumerating objects: 15837, done.\u001b[K\n","remote: Counting objects: 100% (65/65), done.\u001b[K\n","remote: Compressing objects: 100% (51/51), done.\u001b[K\n","remote: Total 15837 (delta 35), reused 14 (delta 14), pack-reused 15772 (from 2)\u001b[K\n","Receiving objects: 100% (15837/15837), 6.41 MiB | 19.36 MiB/s, done.\n","Resolving deltas: 100% (11533/11533), done.\n","Ignoring dataclasses: markers 'python_version < \"3.7\"' don't match your environment\n","Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.11/dist-packages (11.1.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.11/dist-packages (2.0.8)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (2.5.0)\n","Collecting yacs>=0.1.8\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (3.1.1)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Collecting fvcore<0.1.6,>=0.1.5\n","  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting iopath<0.1.10,>=0.1.7\n","  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n","Collecting omegaconf<2.4,>=2.1\n","  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n","Collecting hydra-core>=1.1\n","  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n","Collecting black\n","  Downloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (81 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (24.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs>=0.1.8) (6.0.2)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.71.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.7)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (5.29.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.1.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n","Collecting portalocker (from iopath<0.1.10,>=0.1.7)\n","  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n","Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.4,>=2.1)\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from black) (8.1.8)\n","Collecting mypy-extensions>=0.4.3 (from black)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Collecting pathspec>=0.9.0 (from black)\n","  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black) (4.3.6)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n","Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n","Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n","Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n","Building wheels for collected packages: fvcore, antlr4-python3-runtime\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61396 sha256=77b234b784b8f39a4d429841c9d090f56b642fc10a039e6082e4afde0e44b6d1\n","  Stored in directory: /root/.cache/pip/wheels/65/71/95/3b8fde5c65c6e4a806e0867c1651dcc71a1cb2f3430e8f355f\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=6198c224aada5def909104730bfc47e6bc2a3f80c214f8bdcba2c6ed004ece74\n","  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n","Successfully built fvcore antlr4-python3-runtime\n","Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, black, fvcore\n","Successfully installed antlr4-python3-runtime-4.9.3 black-25.1.0 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.12.1 portalocker-3.1.1 yacs-0.1.8\n"]}],"source":["!python -m pip install pyyaml==5.1\n","import sys, os, distutils.core\n","\n","!git clone 'https://github.com/facebookresearch/detectron2'\n","dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n","!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n","sys.path.insert(0, os.path.abspath('./detectron2'))"]},{"cell_type":"code","source":["import torch, detectron2\n","!nvcc --version\n","TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n","CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n","print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n","print(\"detectron2:\", detectron2.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q_pTimK9kSQl","executionInfo":{"status":"ok","timestamp":1742756913590,"user_tz":240,"elapsed":188,"user":{"displayName":"Chang Liu","userId":"14973576905763553042"}},"outputId":"6a4343ce-3d16-4223-cc50-8764eb0b82a9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2024 NVIDIA Corporation\n","Built on Thu_Jun__6_02:18:23_PDT_2024\n","Cuda compilation tools, release 12.5, V12.5.82\n","Build cuda_12.5.r12.5/compiler.34385749_0\n","torch:  2.6 ; cuda:  cu124\n","detectron2: 0.6\n"]}]},{"cell_type":"code","source":["import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","import numpy as np\n","import os, json, cv2, random\n","from google.colab.patches import cv2_imshow\n","\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog"],"metadata":{"id":"Xz2ZCs2HkTYq","executionInfo":{"status":"ok","timestamp":1742756924108,"user_tz":240,"elapsed":5877,"user":{"displayName":"Chang Liu","userId":"14973576905763553042"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from detectron2.data.datasets import register_coco_instances\n","register_coco_instances(\"my_dataset_train\", {}, \"/content/drive/MyDrive/ESC499/Notehead_Detection/data/train/train.json\", \"/content/drive/MyDrive/ESC499/Notehead_Detection/data/train\")\n","register_coco_instances(\"my_dataset_val\", {}, \"/content/drive/MyDrive/ESC499/Notehead_Detection/data/val/val.json\", \"/content/drive/MyDrive/ESC499/Notehead_Detection/data/val\")\n","\n","train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n","train_dataset_dicts = DatasetCatalog.get(\"my_dataset_train\")\n","val_metadata = MetadataCatalog.get(\"my_dataset_val\")\n","val_dataset_dicts = DatasetCatalog.get(\"my_dataset_val\")\n","\n","\n","from detectron2.engine import DefaultTrainer\n","from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n","from detectron2.data import build_detection_test_loader\n","\n","class TrainerWithEvaluator(DefaultTrainer):\n","    @classmethod\n","    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n","        \"\"\"\n","        Defines the evaluator for validation.\n","        \"\"\"\n","        if output_folder is None:\n","            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n","        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n","\n","\n","cfg = get_cfg()\n","cfg.OUTPUT_DIR = \"/content/drive/MyDrive/ESC499/Notehead_Detection/model_NH\"\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n","cfg.MODEL.MASK_ON = False  # no segmentation field\n","\n","cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n","cfg.DATASETS.TEST = (\"my_dataset_val\",)\n","cfg.TEST.EVAL_PERIOD = 500\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n","\n","cfg.DATALOADER.NUM_WORKERS = 4\n","cfg.SOLVER.IMS_PER_BATCH = 4\n","cfg.SOLVER.BASE_LR = 0.0002\n","cfg.SOLVER.MAX_ITER = 3000\n","cfg.SOLVER.STEPS = [2000, 2500]\n","cfg.SOLVER.GAMMA = 0.5\n","# cfg.SOLVER.WEIGHT_DECAY = 0.0001\n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n","\n","os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","trainer = TrainerWithEvaluator(cfg)         # Create an instance of of DefaultTrainer with the given congiguration\n","trainer.resume_or_load(resume=False)        # Load a pretrained model if available (resume training) or start training from scratch if no pretrained model is available\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"6gGK_TewkUhD","executionInfo":{"status":"ok","timestamp":1742756932517,"user_tz":240,"elapsed":6649,"user":{"displayName":"Chang Liu","userId":"14973576905763553042"}},"outputId":"0b1ddc37-72cf-4dab-f4b3-89100c6b815c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[03/23 19:08:49 d2.data.datasets.coco]: Loading /content/drive/MyDrive/ESC499/Notehead_Detection/data/train/train.json takes 3.65 seconds.\n","[03/23 19:08:49 d2.data.datasets.coco]: Loaded 272 images in COCO format from /content/drive/MyDrive/ESC499/Notehead_Detection/data/train/train.json\n","[03/23 19:08:51 d2.data.datasets.coco]: Loading /content/drive/MyDrive/ESC499/Notehead_Detection/data/val/val.json takes 1.22 seconds.\n","[03/23 19:08:51 d2.data.datasets.coco]: Loaded 70 images in COCO format from /content/drive/MyDrive/ESC499/Notehead_Detection/data/val/val.json\n","[03/23 19:08:52 d2.engine.defaults]: Model:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n","    )\n","  )\n",")\n","[03/23 19:08:52 d2.data.datasets.coco]: Loaded 272 images in COCO format from /content/drive/MyDrive/ESC499/Notehead_Detection/data/train/train.json\n","[03/23 19:08:52 d2.data.build]: Removed 0 images with no usable annotations. 272 images left.\n","[03/23 19:08:52 d2.data.build]: Distribution of instances among all 2 categories:\n","|   category    | #instances   |   category    | #instances   |\n","|:-------------:|:-------------|:-------------:|:-------------|\n","| Empty_Noteh.. | 92           | Full_Notehead | 1422         |\n","|               |              |               |              |\n","|     total     | 1514         |               |              |\n","[03/23 19:08:52 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","[03/23 19:08:52 d2.data.build]: Using training sampler TrainingSampler\n","[03/23 19:08:52 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","[03/23 19:08:52 d2.data.common]: Serializing 272 elements to byte tensors and concatenating them all ...\n","[03/23 19:08:52 d2.data.common]: Serialized dataset takes 0.15 MiB\n","[03/23 19:08:52 d2.data.build]: Making batched data loader with batch_size=4\n","[03/23 19:08:52 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl ...\n"]},{"output_type":"stream","name":"stderr","text":["model_final_280758.pkl: 167MB [00:00, 252MB/s]                           \n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n","roi_heads.box_predictor.bbox_pred.{bias, weight}\n","roi_heads.box_predictor.cls_score.{bias, weight}\n"]}]},{"cell_type":"code","source":["cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9\n","predictor = DefaultPredictor(cfg)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e_W89L44kZ27","executionInfo":{"status":"ok","timestamp":1742756949863,"user_tz":240,"elapsed":11610,"user":{"displayName":"Chang Liu","userId":"14973576905763553042"}},"outputId":"8a2b99e6-e356-410e-ae85-9a191bc800b9"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["[03/23 19:08:59 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /content/drive/MyDrive/ESC499/Notehead_Detection/model_NH/model_final.pth ...\n"]}]},{"cell_type":"code","source":["input_images_directory = \"/content/drive/MyDrive/ESC499/Notehead_Detection/data/test\"\n","output_directory = \"/content/drive/MyDrive/ESC499/Notehead_Detection/data/test_results\"\n","os.makedirs(output_directory, exist_ok=True)\n","\n","for image_filename in os.listdir(input_images_directory):\n","    image_path = os.path.join(input_images_directory, image_filename)\n","    new_im = cv2.imread(image_path)\n","\n","    outputs = predictor(new_im)  # Format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n","\n","    # Use Visualizer to draw the predictions on the image\n","    v = Visualizer(new_im[:, :, ::-1], metadata=train_metadata)\n","    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","\n","    # Create the output filename with _result extension\n","    result_filename = os.path.splitext(image_filename)[0] + \"_result.png\"\n","    output_path = os.path.join(output_directory, result_filename)\n","    # Save the segmented image\n","    cv2.imwrite(output_path, out.get_image()[:, :, ::-1])\n","\n","print(\"Segmentation of all images completed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mYBH_oKDkb00","executionInfo":{"status":"ok","timestamp":1742245572849,"user_tz":240,"elapsed":149852,"user":{"displayName":"Chang Liu","userId":"14973576905763553042"}},"outputId":"2bb183ec-1d12-468a-fab6-4f15906ac760"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"output_type":"stream","name":"stdout","text":["Segmentation of all images completed.\n"]}]},{"cell_type":"code","source":["import csv\n","from detectron2.utils.visualizer import GenericMask\n","\n","input_images_directory = \"/content/drive/MyDrive/ESC499/Notehead_Detection/data/test\"\n","output_csv_path = \"/content/drive/MyDrive/ESC499/Notehead_Detection/data/notehead_detection.csv\"\n","\n","# Open the CSV file\n","with open(output_csv_path, 'w', newline='') as csvfile:\n","    csvwriter = csv.writer(csvfile)\n","\n","    # Write the header row\n","    csvwriter.writerow([\"File Name\", \"Class Name\", \"Object Number\", \"Area\", \"Centroid\", \"BoundingBox\"])\n","\n","    # Iterate over images in the input directory\n","    for image_filename in os.listdir(input_images_directory):\n","        image_path = os.path.join(input_images_directory, image_filename)\n","        new_im = cv2.imread(image_path)\n","\n","        # Perform prediction\n","        outputs = predictor(new_im)\n","        instances = outputs[\"instances\"].to(\"cpu\")\n","\n","        # Extract information from predictions\n","        class_labels = instances.pred_classes.numpy()  # Class IDs\n","        boxes = instances.pred_boxes.tensor.numpy()  # Bounding boxes\n","\n","        for i, box in enumerate(boxes):\n","            # Extract bounding box coordinates\n","            x_min, y_min, x_max, y_max = box\n","\n","            # Compute bounding box area\n","            bbox_area = round(float((x_max - x_min) * (y_max - y_min)), 4)\n","\n","            # Compute centroid\n","            centroid_x = float((x_min + x_max) / 2)\n","            centroid_y = float((y_min + y_max) / 2)\n","            centroid = [round(centroid_x, 3), round(centroid_y, 3)]\n","\n","            # Class name\n","            class_name = train_metadata.thing_classes[class_labels[i]]\n","\n","            # Bounding box with rounded values\n","            bbox_rounded = [round(float(coord), 3) for coord in box]\n","\n","            # Write to CSV\n","            csvwriter.writerow([image_filename, class_name, i + 1, bbox_area, centroid, bbox_rounded])\n","\n","print(f\"Object detection results saved to {output_csv_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bXZxyXSZkku7","executionInfo":{"status":"ok","timestamp":1742757043730,"user_tz":240,"elapsed":89743,"user":{"displayName":"Chang Liu","userId":"14973576905763553042"}},"outputId":"2b1a880c-97dd-4323-a96d-89e00d39a125"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"output_type":"stream","name":"stdout","text":["Object detection results saved to /content/drive/MyDrive/ESC499/Notehead_Detection/data/notehead_detection.csv\n"]}]}]}